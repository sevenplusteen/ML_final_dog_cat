{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#目标score(log loss) <0.06127(RANK 131)\n",
    "#1 数据预处理\n",
    "#2 模型预处理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b1c493a26698>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#from glob import glob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m  \u001b[1;31m#working with images mainly resizing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m  \u001b[1;31m#dealing with arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m \u001b[1;31m#dealing with directories\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "#1.1 导入必要的库\n",
    "#from sklearn.datasets import load_files       \n",
    "#from keras.utils import np_utils\n",
    "#from glob import glob\n",
    "\n",
    "import cv2  #working with images mainly resizing\n",
    "import numpy as np  #dealing with arrays\n",
    "import os #dealing with directories  ？？？\n",
    "from random import shuffle #？？mixing up or currently oredered data that might lead our networ astray in training\n",
    "from tqdm import tqdm  # a nice pretty percentage bar for tasks，就是个进度条...\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2 全局变量\n",
    "IMG_SIZE = 224\n",
    "CHANNELS = 3   #train&test inages resized(224*224*3)\n",
    "\n",
    "LR = 0.01   #learning rate\n",
    "\n",
    "TRAIN_DIR = 'F:/Temp/train/'\n",
    "TEST_DIR = 'F:/Temp/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.3 导入数据及整理\n",
    "\n",
    "def label_img(img):\n",
    "    word_label = img.split('.')[-3]  #以\".\"为分割，从后(-1)往前数第三个（cat.0.jpg）\n",
    "    if word_label == 'cat':return [1,0] \n",
    "    elif word_label == 'dog':return [0,1]\n",
    "    \n",
    "def create_train_and_validation_data ():\n",
    "    original_data = []\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_validation = []\n",
    "    y_validation = []\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):  #os.listdir(path)，返回path指定的文件夹包含的文件名字的列表；用tqdm封装显示处理数据的进度\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(TRAIN_DIR,img)   #os.path.join()将多个路径组合后返回\n",
    "        img = cv2.imread(path,cv2.IMREAD_UNCHANGED)  #cv2.imread()读入图像，cv2.IMREAD_UNCHANGED以读取彩色图片，且包括alpha值(透明度)\n",
    "        img = cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n",
    "        original_data.append([np.array(img),np.array(label)])\n",
    "    shuffle(original_data)\n",
    "    x_train, x_validation, y_train, y_validation = train_test_split(np.array(img),np.array(label),test_size=0.25,random_state=42)\n",
    "    np.save('raw_train_data.npy',original_data)\n",
    "    np.savea('x_train.npy',x_train)\n",
    "    np.save('y_train.npy',y_train)\n",
    "    np.save('x_validation.npy',x_validation)\n",
    "    np.save('y_validation.npy',y_validation)\n",
    "    return x_train, y_train, x_validation, y_validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_data():\n",
    "    testing_data = []\n",
    "    for img in tqdm(os.listdir(TEST_DIR)):\n",
    "        path = os.path.join(TEST_DIR,img)\n",
    "        img_num = img.split('.')[0]\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n",
    "        testing_data.append([np.array(img),img_num])\n",
    "        shuffle(testing_data)\n",
    "        np.save('test_data.npy',tesing_data)\n",
    "        return tesing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [08:43<00:00, 47.78it/s]  \n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_validation, y_validation = create_train_and_validation_data()\n",
    "# If you have already crenated the dataset:\n",
    "#train_data = np.load('train_data.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 预处理模型\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Convolution2D, MaxPooling2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inception V3的效果好于VGG16,而且基于imageNet训练的模型，比较适合图像识别，xception不基于\n",
    "inception_weights_path = '../input/inceptionv3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5'  ###改一下路径，好像可以不用no-top的模型？\n",
    "InceptionV3_model = Sequential\n",
    "InceptionV3_model.add(InceptionV3(include_top = False, pooling = 'avg', weights = inception_weights_path)) # this layer will be set no trainablet\n",
    "InceptionV3_model.add(Dense(2, activation='softmax'))\n",
    "InceptionV3_model.layers[0].trainable #say not to train  first layer model as it is already trained\n",
    "InceptionV3_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#complile model\n",
    "sgd = optimizers.SGD(lr=LR,decay=1e-6, momentum=0.9, nesterov=True) \n",
    "#lrm学习率；momentum动量参数，decay每次更新后的学习率衰减值，nesterov确定是否使用nesterov动量\n",
    "InceptionV3_model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "#这里可能会报错，使用交叉熵需要把数据换成（data,label）?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#train the model\n",
    "checkpointer = ModelCheckpoint(filepath='',verbose=1,save_best_only=True)\n",
    "hist = model.fit(X_train, y_train, batch_size=128,validation_data = (x_validation,y_validation),\n",
    "                 epochs=10,callbacks=[checkpointer],verbose=1,shuffle=True)\n",
    "\n",
    "#优化空间：之一图像增强；之二对CNN网络最后一层（去除了全连接层）进行fine tuning;之三为多增加全连接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize = (15,8)) \n",
    "    \n",
    "plt.subplot(221)  \n",
    "plt.plot(hist.history['acc'])  \n",
    "plt.plot(hist.history['val_acc'])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'valid']) \n",
    "    \n",
    "plt.subplot(222)  \n",
    "plt.plot(hist.history['loss'])  \n",
    "plt.plot(hist.history['val_loss'])  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'valid']) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
